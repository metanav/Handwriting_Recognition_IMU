{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from os import listdir, path\n",
    "import numpy as np\n",
    "import random\n",
    "from collections import defaultdict\n",
    "import datetime\n",
    "                                  \n",
    "random.seed(42)\n",
    "seq_length  = 36\n",
    "num_classes = 10 # 0 to 9\n",
    "dim = 6 # accX,accY,accZ,gyrX,gyrY,gyrZ\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def padding(data):\n",
    "    \"\"\"Get neighboor padding.\"\"\"\n",
    "    padded_data = []\n",
    "    noise_level = [ 20, 20, 20, 0.2, 0.2, 0.2 ]\n",
    "    \n",
    "    # Before- Neighbour padding\n",
    "    tmp_data = (np.random.rand(seq_length, dim) - 0.5) * noise_level + data[0]\n",
    "    tmp_data[(seq_length -\n",
    "              min(len(data), seq_length)):] = data[:min(len(data), seq_length)]\n",
    "    padded_data.append(tmp_data)\n",
    "    # After- Neighbour padding\n",
    "    tmp_data = (np.random.rand(seq_length, dim) - 0.5) * noise_level + data[-1]\n",
    "    tmp_data[:min(len(data), seq_length)] = data[:min(len(data), seq_length)]\n",
    "    padded_data.append(tmp_data)\n",
    "    return padded_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def build_dataset(data, label):\n",
    "    \"\"\"Support function for format.(Helps format train, valid and test.)\"\"\"\n",
    "    # Add 2 padding, initialize data and label\n",
    "    padded_num = 2\n",
    "    length = len(data) * padded_num\n",
    "    features = np.zeros((length, seq_length, dim))\n",
    "    labels = np.zeros(length)\n",
    "    # Get padding for train, valid and test\n",
    "    for idx, (data, label) in enumerate(zip(data, label)):\n",
    "        padded_data = padding(data)\n",
    "        for num in range(padded_num):\n",
    "            features[padded_num * idx + num] = padded_data[num]\n",
    "            labels[padded_num * idx + num] = label\n",
    "    # Turn into tf.data.Dataset\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((features, labels.astype(\"int32\")))\n",
    "    return length, dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def time_warping(molecule, denominator, data):\n",
    "  \"\"\"Generate (molecule/denominator)x speed data.\"\"\"\n",
    "  tmp_data = [[0\n",
    "               for i in range(len(data[0]))]\n",
    "              for j in range((int(len(data) / molecule) - 1) * denominator)]\n",
    "  for i in range(int(len(data) / molecule) - 1):\n",
    "    for j in range(len(data[i])):\n",
    "      for k in range(denominator):\n",
    "        tmp_data[denominator * i +\n",
    "                 k][j] = (data[molecule * i + k][j] * (denominator - k) +\n",
    "                          data[molecule * i + k + 1][j] * k) / denominator\n",
    "  return tmp_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def augment_data(original_data, original_label):\n",
    "  \"\"\"Perform data augmentation.\"\"\"\n",
    "  new_data = []\n",
    "  new_label = []\n",
    "  for idx, (data, label) in enumerate(zip(original_data, original_label)):  # pylint: disable=unused-variable\n",
    "    # Original data\n",
    "    new_data.append(data)\n",
    "    new_label.append(label)\n",
    "    # Sequence shift\n",
    "    for num in range(5):  # pylint: disable=unused-variable\n",
    "      new_data.append((np.array(data, dtype=np.float32) +\n",
    "                       (random.random() - 0.5) * 200).tolist())\n",
    "      new_label.append(label)\n",
    "    # Random noise\n",
    "    tmp_data = [[0 for i in range(len(data[0]))] for j in range(len(data))]\n",
    "    for num in range(5):\n",
    "      for i in range(len(tmp_data)):\n",
    "        for j in range(len(tmp_data[i])):\n",
    "          tmp_data[i][j] = data[i][j] + 5 * random.random()\n",
    "      new_data.append(tmp_data)\n",
    "      new_label.append(label)\n",
    "    # Time warping\n",
    "    fractions = [(3, 2), (5, 3), (2, 3), (3, 4), (9, 5), (6, 5), (4, 5)]\n",
    "    for molecule, denominator in fractions:\n",
    "      new_data.append(time_warping(molecule, denominator, data))\n",
    "      new_label.append(label)\n",
    "    # Movement amplification\n",
    "    for molecule, denominator in fractions:\n",
    "      new_data.append(\n",
    "          (np.array(data, dtype=np.float32) * molecule / denominator).tolist())\n",
    "      new_label.append(label)\n",
    "  return new_data, new_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def load_data(data_type, files):\n",
    "    data   = []\n",
    "    labels = []\n",
    "    random.shuffle(files)\n",
    "   \n",
    "    for file in files:\n",
    "        with open(file) as f:\n",
    "            label = path.splitext(file)[0][-1]\n",
    "            labels.append(label)\n",
    "            readings = []\n",
    "            for line in f:\n",
    "                reading = line.strip().split(',')\n",
    "                readings.append([float(i) for i in reading[0:6]])\n",
    "\n",
    "            data.append(readings)\n",
    "            \n",
    "    if data_type == 'train':\n",
    "        data, labels = augment_data(data, labels)\n",
    "    \n",
    "    return build_dataset(data, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22200 290 312\n",
      "tf.Tensor(\n",
      "[[ 8.62218550e+02  2.14691843e+02  7.33347481e+02 -6.70498390e+00\n",
      "  -8.70778775e+00 -2.16604876e+01]\n",
      " [ 8.52860236e+02  2.23494644e+02  7.39960521e+02 -6.56941050e+00\n",
      "  -8.72773746e+00 -2.15468501e+01]\n",
      " [ 8.66868736e+02  2.09782966e+02  7.29041796e+02 -6.59991350e+00\n",
      "  -8.68658239e+00 -2.16797709e+01]\n",
      " [ 8.68028236e+02  2.25161774e+02  7.25009907e+02 -6.58862671e+00\n",
      "  -8.80797946e+00 -2.16260231e+01]\n",
      " [ 8.51485842e+02  2.23154272e+02  7.29396976e+02 -6.63546198e+00\n",
      "  -8.79622833e+00 -2.15226978e+01]\n",
      " [ 8.50965643e+02  2.10079153e+02  7.24618299e+02 -6.67961745e+00\n",
      "  -8.62681530e+00 -2.15870825e+01]\n",
      " [ 8.53347917e+02  2.26176597e+02  7.38116982e+02 -6.51793153e+00\n",
      "  -8.68970041e+00 -2.16693844e+01]\n",
      " [ 8.53488090e+02  2.17294139e+02  7.29503386e+02 -6.58085326e+00\n",
      "  -8.71020467e+00 -2.16735914e+01]\n",
      " [ 8.63223763e+02  2.21538970e+02  7.39704110e+02 -6.67661895e+00\n",
      "  -8.76696546e+00 -2.16423769e+01]\n",
      " [ 8.54412862e+02  2.06821531e+02  7.27370296e+02 -6.51437605e+00\n",
      "  -8.65258853e+00 -2.16530314e+01]\n",
      " [ 8.48761295e+02  2.12003318e+02  7.29639151e+02 -6.57943746e+00\n",
      "  -8.61534511e+00 -2.15522118e+01]\n",
      " [ 8.66067595e+02  2.25547900e+02  7.35392621e+02 -6.59019741e+00\n",
      "  -8.63292162e+00 -2.15824546e+01]\n",
      " [ 8.53611384e+02  2.23102478e+02  7.27131049e+02 -6.67080624e+00\n",
      "  -8.71955477e+00 -2.16042360e+01]\n",
      " [ 8.52571986e+02  2.16820879e+02  7.22135042e+02 -6.66505835e+00\n",
      "  -8.76309764e+00 -2.16055457e+01]\n",
      " [ 8.49027394e+02  2.22244923e+02  7.25731463e+02 -6.59196358e+00\n",
      "  -8.75771000e+00 -2.16461839e+01]\n",
      " [ 8.63713437e+02  2.22665496e+02  7.37699653e+02 -6.61274717e+00\n",
      "  -8.65036065e+00 -2.16670065e+01]\n",
      " [ 8.58400000e+02  2.16800000e+02  7.31930000e+02 -6.61000000e+00\n",
      "  -8.71000000e+00 -2.16000000e+01]\n",
      " [ 1.06299000e+03  6.49900000e+02  3.11520000e+02 -3.95500000e+01\n",
      "  -2.33500000e+01 -2.26600000e+01]\n",
      " [ 8.05180000e+02  2.31450000e+02  2.97360000e+02 -1.36300000e+01\n",
      "  -1.37700000e+01 -4.24200000e+01]\n",
      " [ 1.29390000e+02 -1.87500000e+02  2.44000000e+00 -1.58200000e+01\n",
      "  -1.22100000e+01 -3.51800000e+01]\n",
      " [ 9.52640000e+02  1.32320000e+02  8.10550000e+02 -1.56600000e+01\n",
      "  -6.19000000e+00 -1.71200000e+01]\n",
      " [ 8.12990000e+02  3.81350000e+02  2.80760000e+02 -8.85000000e+00\n",
      "  -7.30000000e+00  6.53000000e+00]\n",
      " [ 9.21390000e+02  2.91990000e+02  3.66700000e+02  2.40000000e+00\n",
      "   1.24000000e+00 -2.20000000e-01]\n",
      " [ 9.81450000e+02 -9.91200000e+01  1.48440000e+02  6.50000000e+00\n",
      "  -7.98000000e+00 -1.05400000e+01]\n",
      " [ 1.15283000e+03  5.69340000e+02  9.69730000e+02 -1.40700000e+01\n",
      "  -3.08300000e+01  2.20100000e+01]\n",
      " [ 7.63670000e+02 -2.03610000e+02 -4.09180000e+02 -2.64400000e+01\n",
      "  -4.15600000e+01  4.39900000e+01]\n",
      " [ 9.04790000e+02 -9.91200000e+01  1.30860000e+02 -1.60300000e+01\n",
      "  -6.55600000e+01  5.32700000e+01]\n",
      " [ 9.09180000e+02 -1.83590000e+02 -5.55180000e+02 -1.82100000e+01\n",
      "  -6.53800000e+01  5.33400000e+01]\n",
      " [ 1.06689000e+03 -1.81640000e+02  1.15820000e+03 -8.60000000e+00\n",
      "  -4.72300000e+01  4.34400000e+01]\n",
      " [ 1.07031000e+03  4.42870000e+02  6.82130000e+02  1.34900000e+01\n",
      "  -2.71800000e+01  2.57300000e+01]\n",
      " [ 5.69820000e+02 -5.13180000e+02  6.97270000e+02  2.00000000e-02\n",
      "  -8.53000000e+00 -5.60000000e-01]\n",
      " [ 9.29200000e+02 -7.76400000e+01  2.33400000e+02 -2.03200000e+01\n",
      "   8.10000000e-01  9.06000000e+00]\n",
      " [ 8.96000000e+02 -6.64100000e+01  3.91110000e+02 -3.16700000e+01\n",
      "  -2.85000000e+00  1.07200000e+01]\n",
      " [ 9.43360000e+02 -1.60160000e+02  3.18850000e+02 -3.30000000e+01\n",
      "  -2.17200000e+01  1.17000000e+01]\n",
      " [ 9.43360000e+02 -1.48930000e+02  2.98340000e+02  5.05000000e+00\n",
      "  -1.82300000e+01  1.11000000e+00]\n",
      " [ 9.64840000e+02 -1.35740000e+02  2.87600000e+02  2.00600000e+01\n",
      "  -5.85000000e+00 -4.29000000e+00]], shape=(36, 6), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "files_path = defaultdict(list)\n",
    "dir = './data'\n",
    "for filename in listdir(dir):\n",
    "    if filename.endswith('.csv'): #or filename.endswith('1.csv')  or filename.endswith('2.csv')  or filename.endswith('3.csv')  or filename.endswith('4.csv'):\n",
    "        digit = path.splitext(filename)[0][-1]\n",
    "        files_path[digit].append(path.join(dir, filename))\n",
    "\n",
    "train_files      = []\n",
    "validation_files = []\n",
    "test_files       = []\n",
    "\n",
    "for digit in files_path:\n",
    "    random.shuffle(files_path[digit])\n",
    "    \n",
    "    train_split = int(len(files_path[digit]) * 0.6) # 60%\n",
    "    validation_split = train_split + int(len(files_path[digit]) * 0.2) # 20%\n",
    "\n",
    "    train_files += files_path[digit][:train_split]\n",
    "    validation_files += files_path[digit][train_split:validation_split]\n",
    "    # remaining 20%\n",
    "    test_files += files_path[digit][validation_split:]\n",
    "\n",
    "train_length, train_data = load_data('train', train_files)\n",
    "validation_length, validation_data = load_data('validation', validation_files)\n",
    "test_length, test_data = load_data('test', test_files )\n",
    "\n",
    "print(train_length, validation_length, test_length)\n",
    "\n",
    "for (ds, lb) in test_data.take(1):\n",
    "    print(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "      tf.keras.layers.Conv2D(8, (3, 3), padding=\"same\", activation=\"relu\", input_shape=(seq_length, dim, 1)),\n",
    "      tf.keras.layers.Conv2D(8, (3, 3), padding=\"same\", activation=\"relu\"),\n",
    "      tf.keras.layers.MaxPool2D((2, 2)),\n",
    "      tf.keras.layers.Dropout(0.1),\n",
    "      tf.keras.layers.Conv2D(8, (3, 3), padding=\"same\", activation=\"relu\"),\n",
    "      tf.keras.layers.MaxPool2D((2, 2), padding=\"same\"),\n",
    "      tf.keras.layers.Dropout(0.1),\n",
    "      tf.keras.layers.Conv2D(16, (3, 3), padding=\"same\", activation=\"relu\"),\n",
    "      tf.keras.layers.MaxPool2D((2, 2), padding=\"same\"),\n",
    "      tf.keras.layers.Dropout(0.1),\n",
    "      tf.keras.layers.Conv2D(16, (3, 3), padding=\"same\", activation=\"relu\"),\n",
    "      tf.keras.layers.Flatten(),\n",
    "      tf.keras.layers.Dense(64, activation=\"relu\"),\n",
    "      tf.keras.layers.Dropout(0.2),\n",
    "      tf.keras.layers.Dense(32, activation=\"relu\"),\n",
    "      tf.keras.layers.Dropout(0.2),\n",
    "      tf.keras.layers.Dense(num_classes, activation=\"softmax\")\n",
    "  ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 36, 6, 8)          80        \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 36, 6, 8)          584       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 18, 3, 8)          0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 18, 3, 8)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 18, 3, 8)          584       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 9, 2, 8)           0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 9, 2, 8)           0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 9, 2, 16)          1168      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 5, 1, 16)          0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 5, 1, 16)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 5, 1, 16)          2320      \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 80)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                5184      \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                330       \n",
      "=================================================================\n",
      "Total params: 12,330\n",
      "Trainable params: 12,330\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 1000 steps, validate for 5 steps\n",
      "Epoch 1/100\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 2.9807 - accuracy: 0.1402 - val_loss: 2.1285 - val_accuracy: 0.1828\n",
      "Epoch 2/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 2.0924 - accuracy: 0.1999 - val_loss: 1.8769 - val_accuracy: 0.2862\n",
      "Epoch 3/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 1.8780 - accuracy: 0.3077 - val_loss: 1.6219 - val_accuracy: 0.4414\n",
      "Epoch 4/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 1.6085 - accuracy: 0.4414 - val_loss: 1.3866 - val_accuracy: 0.5931\n",
      "Epoch 5/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 1.3297 - accuracy: 0.5515 - val_loss: 1.0012 - val_accuracy: 0.6931\n",
      "Epoch 6/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 1.1468 - accuracy: 0.6195 - val_loss: 0.8652 - val_accuracy: 0.7552\n",
      "Epoch 7/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 1.0249 - accuracy: 0.6645 - val_loss: 0.6714 - val_accuracy: 0.8034\n",
      "Epoch 8/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.9235 - accuracy: 0.6974 - val_loss: 0.6992 - val_accuracy: 0.7793\n",
      "Epoch 9/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.8399 - accuracy: 0.7274 - val_loss: 0.5927 - val_accuracy: 0.8448\n",
      "Epoch 10/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.7678 - accuracy: 0.7526 - val_loss: 0.5206 - val_accuracy: 0.8379\n",
      "Epoch 11/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.6955 - accuracy: 0.7745 - val_loss: 0.4586 - val_accuracy: 0.8414\n",
      "Epoch 12/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.6468 - accuracy: 0.7925 - val_loss: 0.5718 - val_accuracy: 0.8103\n",
      "Epoch 13/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.5809 - accuracy: 0.8130 - val_loss: 0.4674 - val_accuracy: 0.8655\n",
      "Epoch 14/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.5423 - accuracy: 0.8254 - val_loss: 0.3960 - val_accuracy: 0.8724\n",
      "Epoch 15/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.5144 - accuracy: 0.8336 - val_loss: 0.3703 - val_accuracy: 0.8966\n",
      "Epoch 16/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4791 - accuracy: 0.8461 - val_loss: 0.3210 - val_accuracy: 0.8897\n",
      "Epoch 17/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4540 - accuracy: 0.8527 - val_loss: 0.3598 - val_accuracy: 0.9034\n",
      "Epoch 18/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4253 - accuracy: 0.8605 - val_loss: 0.3946 - val_accuracy: 0.9000\n",
      "Epoch 19/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4235 - accuracy: 0.8630 - val_loss: 0.3651 - val_accuracy: 0.9000\n",
      "Epoch 20/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4023 - accuracy: 0.8709 - val_loss: 0.4049 - val_accuracy: 0.8724\n",
      "Epoch 21/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3841 - accuracy: 0.8760 - val_loss: 0.2296 - val_accuracy: 0.9414\n",
      "Epoch 22/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3658 - accuracy: 0.8821 - val_loss: 0.2885 - val_accuracy: 0.9138\n",
      "Epoch 23/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3666 - accuracy: 0.8813 - val_loss: 0.4761 - val_accuracy: 0.8966\n",
      "Epoch 24/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3558 - accuracy: 0.8861 - val_loss: 0.3467 - val_accuracy: 0.9172\n",
      "Epoch 25/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3387 - accuracy: 0.8907 - val_loss: 0.2622 - val_accuracy: 0.9310\n",
      "Epoch 26/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3443 - accuracy: 0.8898 - val_loss: 0.4503 - val_accuracy: 0.9207\n",
      "Epoch 27/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3372 - accuracy: 0.8910 - val_loss: 0.3082 - val_accuracy: 0.9345\n",
      "Epoch 28/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3173 - accuracy: 0.8957 - val_loss: 0.3121 - val_accuracy: 0.9276\n",
      "Epoch 29/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3198 - accuracy: 0.8962 - val_loss: 0.3010 - val_accuracy: 0.9207\n",
      "Epoch 30/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3011 - accuracy: 0.9022 - val_loss: 0.1846 - val_accuracy: 0.9345\n",
      "Epoch 31/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3039 - accuracy: 0.9013 - val_loss: 0.2444 - val_accuracy: 0.9310\n",
      "Epoch 32/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.2994 - accuracy: 0.9027 - val_loss: 0.2776 - val_accuracy: 0.9310\n",
      "Epoch 33/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.2849 - accuracy: 0.9063 - val_loss: 0.2022 - val_accuracy: 0.9483\n",
      "Epoch 34/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.2937 - accuracy: 0.9057 - val_loss: 0.3361 - val_accuracy: 0.9414\n",
      "Epoch 35/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.2806 - accuracy: 0.9081 - val_loss: 0.2726 - val_accuracy: 0.9414\n",
      "Epoch 36/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.2767 - accuracy: 0.9103 - val_loss: 0.2967 - val_accuracy: 0.9414\n",
      "Epoch 37/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.2736 - accuracy: 0.9117 - val_loss: 0.2829 - val_accuracy: 0.9276\n",
      "Epoch 38/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.2674 - accuracy: 0.9130 - val_loss: 0.2505 - val_accuracy: 0.9483\n",
      "Epoch 39/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.2692 - accuracy: 0.9130 - val_loss: 0.1848 - val_accuracy: 0.9207\n",
      "Epoch 40/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.2630 - accuracy: 0.9141 - val_loss: 0.3234 - val_accuracy: 0.9276\n",
      "Epoch 41/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.2551 - accuracy: 0.9173 - val_loss: 0.2129 - val_accuracy: 0.9517\n",
      "Epoch 42/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.2520 - accuracy: 0.9185 - val_loss: 0.2535 - val_accuracy: 0.9483\n",
      "Epoch 43/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.2505 - accuracy: 0.9188 - val_loss: 0.3464 - val_accuracy: 0.9310\n",
      "Epoch 44/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.2522 - accuracy: 0.9176 - val_loss: 0.2511 - val_accuracy: 0.9379\n",
      "Epoch 45/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.2513 - accuracy: 0.9177 - val_loss: 0.1913 - val_accuracy: 0.9310\n",
      "Epoch 46/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.2462 - accuracy: 0.9190 - val_loss: 0.1883 - val_accuracy: 0.9517\n",
      "Epoch 47/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.2420 - accuracy: 0.9205 - val_loss: 0.1523 - val_accuracy: 0.9586\n",
      "Epoch 48/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.2410 - accuracy: 0.9228 - val_loss: 0.2269 - val_accuracy: 0.9448\n",
      "Epoch 49/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.2278 - accuracy: 0.9259 - val_loss: 0.2180 - val_accuracy: 0.9414\n",
      "Epoch 50/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.2240 - accuracy: 0.9288 - val_loss: 0.1927 - val_accuracy: 0.9448\n",
      "Epoch 51/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.2247 - accuracy: 0.9267 - val_loss: 0.2178 - val_accuracy: 0.9552\n",
      "Epoch 52/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.2223 - accuracy: 0.9286 - val_loss: 0.2662 - val_accuracy: 0.9483\n",
      "Epoch 53/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.2231 - accuracy: 0.9292 - val_loss: 0.2251 - val_accuracy: 0.9483\n",
      "Epoch 54/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.2201 - accuracy: 0.9283 - val_loss: 0.2753 - val_accuracy: 0.9414\n",
      "Epoch 55/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.2139 - accuracy: 0.9305 - val_loss: 0.2474 - val_accuracy: 0.9379\n",
      "Epoch 56/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.2173 - accuracy: 0.9301 - val_loss: 0.1787 - val_accuracy: 0.9310\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.2096 - accuracy: 0.9330 - val_loss: 0.2791 - val_accuracy: 0.9414\n",
      "Epoch 58/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.2075 - accuracy: 0.9332 - val_loss: 0.2939 - val_accuracy: 0.9345\n",
      "Epoch 59/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.2072 - accuracy: 0.9322 - val_loss: 0.2664 - val_accuracy: 0.9552\n",
      "Epoch 60/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.2082 - accuracy: 0.9334 - val_loss: 0.4275 - val_accuracy: 0.9276\n",
      "Epoch 61/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.2077 - accuracy: 0.9327 - val_loss: 0.3687 - val_accuracy: 0.9448\n",
      "Epoch 62/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.2000 - accuracy: 0.9370 - val_loss: 0.2534 - val_accuracy: 0.9483\n",
      "Epoch 63/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.2039 - accuracy: 0.9340 - val_loss: 0.2295 - val_accuracy: 0.9310\n",
      "Epoch 64/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.2000 - accuracy: 0.9352 - val_loss: 0.1813 - val_accuracy: 0.9552\n",
      "Epoch 65/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1960 - accuracy: 0.9376 - val_loss: 0.2426 - val_accuracy: 0.9621\n",
      "Epoch 66/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1957 - accuracy: 0.9378 - val_loss: 0.2073 - val_accuracy: 0.9414\n",
      "Epoch 67/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1982 - accuracy: 0.9371 - val_loss: 0.2164 - val_accuracy: 0.9552\n",
      "Epoch 68/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1973 - accuracy: 0.9378 - val_loss: 0.3298 - val_accuracy: 0.9448\n",
      "Epoch 69/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1844 - accuracy: 0.9403 - val_loss: 0.3380 - val_accuracy: 0.9552\n",
      "Epoch 70/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1917 - accuracy: 0.9384 - val_loss: 0.2683 - val_accuracy: 0.9379\n",
      "Epoch 71/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1959 - accuracy: 0.9386 - val_loss: 0.2561 - val_accuracy: 0.9414\n",
      "Epoch 72/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1927 - accuracy: 0.9389 - val_loss: 0.2253 - val_accuracy: 0.9483\n",
      "Epoch 73/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1869 - accuracy: 0.9398 - val_loss: 0.1774 - val_accuracy: 0.9483\n",
      "Epoch 74/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1813 - accuracy: 0.9432 - val_loss: 0.3925 - val_accuracy: 0.9310\n",
      "Epoch 75/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1901 - accuracy: 0.9404 - val_loss: 0.2484 - val_accuracy: 0.9483\n",
      "Epoch 76/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1826 - accuracy: 0.9413 - val_loss: 0.2376 - val_accuracy: 0.9517\n",
      "Epoch 77/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1841 - accuracy: 0.9408 - val_loss: 0.2789 - val_accuracy: 0.9552\n",
      "Epoch 78/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1834 - accuracy: 0.9413 - val_loss: 0.2609 - val_accuracy: 0.9483\n",
      "Epoch 79/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1759 - accuracy: 0.9438 - val_loss: 0.2228 - val_accuracy: 0.9483\n",
      "Epoch 80/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1850 - accuracy: 0.9425 - val_loss: 0.1959 - val_accuracy: 0.9448\n",
      "Epoch 81/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1804 - accuracy: 0.9414 - val_loss: 0.1896 - val_accuracy: 0.9345\n",
      "Epoch 82/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1846 - accuracy: 0.9411 - val_loss: 0.2990 - val_accuracy: 0.9414\n",
      "Epoch 83/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1642 - accuracy: 0.9466 - val_loss: 0.2235 - val_accuracy: 0.9517\n",
      "Epoch 84/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1769 - accuracy: 0.9438 - val_loss: 0.2375 - val_accuracy: 0.9448\n",
      "Epoch 85/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1786 - accuracy: 0.9431 - val_loss: 0.3729 - val_accuracy: 0.9379\n",
      "Epoch 86/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1782 - accuracy: 0.9433 - val_loss: 0.3715 - val_accuracy: 0.9414\n",
      "Epoch 87/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1728 - accuracy: 0.9461 - val_loss: 0.2895 - val_accuracy: 0.9345\n",
      "Epoch 88/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1835 - accuracy: 0.9413 - val_loss: 0.2654 - val_accuracy: 0.9379\n",
      "Epoch 89/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1728 - accuracy: 0.9439 - val_loss: 0.2209 - val_accuracy: 0.9552\n",
      "Epoch 90/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1786 - accuracy: 0.9430 - val_loss: 0.2041 - val_accuracy: 0.9414\n",
      "Epoch 91/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1708 - accuracy: 0.9448 - val_loss: 0.3307 - val_accuracy: 0.9379\n",
      "Epoch 92/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1735 - accuracy: 0.9450 - val_loss: 0.1948 - val_accuracy: 0.9517\n",
      "Epoch 93/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1735 - accuracy: 0.9451 - val_loss: 0.2454 - val_accuracy: 0.9621\n",
      "Epoch 94/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1639 - accuracy: 0.9481 - val_loss: 0.3262 - val_accuracy: 0.9379\n",
      "Epoch 95/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1730 - accuracy: 0.9442 - val_loss: 0.3102 - val_accuracy: 0.9379\n",
      "Epoch 96/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1631 - accuracy: 0.9482 - val_loss: 0.2405 - val_accuracy: 0.9379\n",
      "Epoch 97/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1617 - accuracy: 0.9470 - val_loss: 0.1871 - val_accuracy: 0.9448\n",
      "Epoch 98/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1716 - accuracy: 0.9454 - val_loss: 0.1743 - val_accuracy: 0.9621\n",
      "Epoch 99/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1698 - accuracy: 0.9467 - val_loss: 0.3659 - val_accuracy: 0.9448\n",
      "Epoch 100/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1636 - accuracy: 0.9483 - val_loss: 0.2232 - val_accuracy: 0.9448\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7ff1caec83c8>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs = 100\n",
    "batch_size = 64\n",
    "steps_per_epoch=1000\n",
    "\n",
    "model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "def reshape_function(data, label):\n",
    "  reshaped_data = tf.reshape(data, [-1, dim, 1])\n",
    "  return reshaped_data, label\n",
    "\n",
    "train_data = train_data.map(reshape_function)\n",
    "validation_data = validation_data.map(reshape_function)\n",
    "\n",
    "train_data = train_data.batch(batch_size).repeat()\n",
    "validation_data = validation_data.batch(batch_size)\n",
    "\n",
    "logdir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=logdir)\n",
    "# %load_ext tensorboard\n",
    "# %tensorboard --logdir logdir\n",
    "\n",
    "model.fit(\n",
    "  train_data,\n",
    "  epochs=epochs,\n",
    "  validation_data=validation_data,\n",
    "  steps_per_epoch=steps_per_epoch,\n",
    "  validation_steps=int((validation_length - 1) / batch_size + 1),\n",
    "  callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2605 - accuracy: 0.9327\n",
      "tf.Tensor(\n",
      "[[34  0  0  0  0  0  6  0  0  0]\n",
      " [ 0 36  0  0  0  0  0  0  0  0]\n",
      " [ 0  0 39  0  0  0  1  0  0  0]\n",
      " [ 0  0  0 40  0  0  0  0  0  0]\n",
      " [ 0  0  0  0 44  0  0  0  0  0]\n",
      " [ 0  0  0  0  0 40  0  0  0  0]\n",
      " [ 4  0  0  0  0  0 38  0  0  0]\n",
      " [ 1  0  1  0  0  0  0  7  0  1]\n",
      " [ 0  0  1  0  0  0  1  0  8  0]\n",
      " [ 0  0  0  0  0  0  2  3  0  5]], shape=(10, 10), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "test_data = test_data.map(reshape_function)\n",
    "test_labels = np.zeros(test_length)\n",
    "\n",
    "idx = 0\n",
    "for data, label in test_data:\n",
    "    test_labels[idx] = label.numpy()\n",
    "    idx += 1\n",
    "    \n",
    "test_data = test_data.batch(batch_size)\n",
    "\n",
    "loss, acc = model.evaluate(test_data)\n",
    "pred = np.argmax(model.predict(test_data), axis=1)\n",
    "confusion = tf.math.confusion_matrix(labels=tf.constant(test_labels), predictions=tf.constant(pred), num_classes=num_classes)\n",
    "print(confusion)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21544"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "tflite_model = converter.convert()\n",
    "open(\"model.tflite\", \"wb\").write(tflite_model)\n",
    "\n",
    "# Convert the model to the TensorFlow Lite format with quantization\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "converter.optimizations = [tf.lite.Optimize.OPTIMIZE_FOR_SIZE]\n",
    "tflite_model = converter.convert()\n",
    "open(\"model_quantized.tflite\", \"wb\").write(tflite_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
